{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 膨胀网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from PIL import Image\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不变\n",
    "original = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "#缩小\n",
    "zoom_out = T.Compose([\n",
    "    T.Resize(14),\n",
    "    T.Pad(7),\n",
    "    T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def get_mnist_dataloader(transforms, batch_size, shuffle=False, if_print=False):\n",
    "    set_train = dset.MNIST('../MNIST', train=True, transform=transforms, download=False)\n",
    "    loader_train = DataLoader(set_train, batch_size=batch_size, shuffle=shuffle)\n",
    "    set_test = dset.MNIST('../MNIST', train=False, transform=transforms,download=False)\n",
    "    loader_test = DataLoader(set_test, batch_size=batch_size, shuffle=shuffle)\n",
    "    if if_print:\n",
    "        print(\"训练集大小：\",set_train.train_data.size())\n",
    "        print(\"训练集标签：\",set_train.train_labels.size())\n",
    "        print(\"测试集大小：\",set_test.test_data.size())\n",
    "        print(\"测试集标签：\",set_test.test_labels.size())\n",
    "    return loader_train, loader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show imgs on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： torch.Size([60000, 28, 28])\n",
      "训练集标签： torch.Size([60000])\n",
      "测试集大小： torch.Size([10000, 28, 28])\n",
      "测试集标签： torch.Size([10000])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "tr_original, te_original = get_mnist_dataloader(original, 64, if_print=True)\n",
    "tr_zoom_out, te_zoom_out = get_mnist_dataloader(zoom_out, 64)\n",
    "\n",
    "test_imgs = next(iter(te_original))\n",
    "print(test_imgs[0].shape)\n",
    "writer = SummaryWriter()\n",
    "writer.add_image('Image', test_imgs[0], 1)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "    \n",
    "def train(model, train_data, test_data, num_epochs = 1, print_every = 200):\n",
    "    model.apply(reset)\n",
    "    loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        check_accuracy(model, test_data)\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(train_data):\n",
    "            x_var = Variable(x.cuda())\n",
    "            y_var = Variable(y.cuda().long())\n",
    "            scores = model(x_var)        \n",
    "            loss = loss_fn(scores, y_var) \n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "    print(\"\\n原始样本精确度\")\n",
    "    check_accuracy(model, te_original)\n",
    "    print(\"缩小样本精确度\")\n",
    "    check_accuracy(model, te_zoom_out)\n",
    "            \n",
    "def check_accuracy(model, test_data):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() \n",
    "    for x, y in test_data:\n",
    "        x_var = Variable(x.cuda(), volatile=True)\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "class NaiveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NaiveNet, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "naive_net = NaiveNet().cuda()\n",
    "\n",
    "input = Variable(torch.randn(5, 1, 28, 28)).cuda()\n",
    "out = naive_net(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "Got 974 / 10000 correct (9.74)\n",
      "t = 200, loss = 0.4944\n",
      "t = 400, loss = 0.2003\n",
      "t = 600, loss = 0.1968\n",
      "t = 800, loss = 0.2129\n",
      "Starting epoch 2 / 5\n",
      "Got 9597 / 10000 correct (95.97)\n",
      "t = 200, loss = 0.0931\n",
      "t = 400, loss = 0.1760\n",
      "t = 600, loss = 0.1170\n",
      "t = 800, loss = 0.1408\n",
      "Starting epoch 3 / 5\n",
      "Got 9717 / 10000 correct (97.17)\n",
      "t = 200, loss = 0.0721\n",
      "t = 400, loss = 0.1253\n",
      "t = 600, loss = 0.0923\n",
      "t = 800, loss = 0.1152\n",
      "Starting epoch 4 / 5\n",
      "Got 9813 / 10000 correct (98.13)\n",
      "t = 200, loss = 0.0519\n",
      "t = 400, loss = 0.1149\n",
      "t = 600, loss = 0.0900\n",
      "t = 800, loss = 0.0669\n",
      "Starting epoch 5 / 5\n",
      "Got 9851 / 10000 correct (98.51)\n",
      "t = 200, loss = 0.0193\n",
      "t = 400, loss = 0.1125\n",
      "t = 600, loss = 0.0771\n",
      "t = 800, loss = 0.0363\n",
      "\n",
      " 原始样本精确度\n",
      "Got 4820 / 10000 correct (48.20)\n",
      "缩小样本精确度\n",
      "Got 9869 / 10000 correct (98.69)\n"
     ]
    }
   ],
   "source": [
    "# 训练naive_net\n",
    "train(naive_net, \n",
    "      tr_zoom_out,\n",
    "      te_zoom_out, \n",
    "      num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(naive_net.state_dict(),\"naive_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_net.load_state_dict(torch.load(\"naive_net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 24, 24])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(5, 1, 28, 28)).cuda()\n",
    "m = nn.Conv2d(1,64,5).cuda()\n",
    "y = m(input)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 24, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(5, 1, 28, 28)).cuda()\n",
    "m = nn.Conv2d(1,64,5,dilation=2,padding=2).cuda()\n",
    "y = m(input)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DilateNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "class DilateNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DilateNet, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(1,64,5,dilation=2,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64,64,3,dilation=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64,64,3,dilation=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "dilate_net = DilateNet().cuda()\n",
    "\n",
    "input = Variable(torch.randn(5, 1, 28, 28)).cuda()\n",
    "out = dilate_net(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原始样本精确度\n",
      "Got 4820 / 10000 correct (48.20)\n",
      "缩小样本精确度\n",
      "Got 9869 / 10000 correct (98.69)\n"
     ]
    }
   ],
   "source": [
    "naive_net.load_state_dict(torch.load(\"naive_net\"))\n",
    "print(\"\\n原始样本精确度\")\n",
    "check_accuracy(naive_net, te_original)\n",
    "print(\"缩小样本精确度\")\n",
    "check_accuracy(naive_net, te_zoom_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原始样本精确度\n",
      "Got 9151 / 10000 correct (91.51)\n",
      "缩小样本精确度\n",
      "Got 3764 / 10000 correct (37.64)\n"
     ]
    }
   ],
   "source": [
    "dilate_net.load_state_dict(torch.load(\"naive_net\"))\n",
    "print(\"\\n原始样本精确度\")\n",
    "check_accuracy(dilate_net, te_original)\n",
    "print(\"缩小样本精确度\")\n",
    "check_accuracy(dilate_net, te_zoom_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积盒子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBox1(nn.Module):\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        super(ConvBox1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(1, 64, 5, dilation=2, padding=2)\n",
    "        self.conv1.weight.data = w\n",
    "        self.conv1.bias.data = b\n",
    "        self.conv2.weight.data = w\n",
    "        self.conv2.bias.data = b\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        #y = torch.max(x1, x2)\n",
    "        #y = x1 + x2\n",
    "        return y\n",
    "    \n",
    "class ConvBox2(ConvBox1):\n",
    "\n",
    "    def __init__(self, w, b):\n",
    "        super(ConvBox2, self).__init__(w, b)\n",
    "        self.conv1 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, dilation=2, padding=1)\n",
    "        self.conv1.weight.data = w\n",
    "        self.conv1.bias.data = b\n",
    "        self.conv2.weight.data = w\n",
    "        self.conv2.bias.data = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 10, 10])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = naive_net.feature[3].weight.data\n",
    "b = naive_net.feature[3].bias.data\n",
    "\n",
    "input = Variable(torch.randn(5, 64, 12, 12)).cuda()\n",
    "\n",
    "s = ConvBox2(w,b).cuda()\n",
    "s(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "class DilateNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DilateNet2, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            ConvBox1(naive_net.feature[0].weight.data,\n",
    "                     naive_net.feature[0].bias.data),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            ConvBox2(naive_net.feature[3].weight.data,\n",
    "                     naive_net.feature[3].bias.data),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            ConvBox2(naive_net.feature[6].weight.data,\n",
    "                     naive_net.feature[6].bias.data),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "        self.fc1.weight.data = naive_net.classifier[0].weight.data\n",
    "        self.fc1.bias.data = naive_net.classifier[0].bias.data\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "dilate_net2 = DilateNet2().cuda()\n",
    "\n",
    "input = Variable(torch.randn(5, 1, 28, 28)).cuda()\n",
    "out = dilate_net2(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原始样本精确度\n",
      "Got 9151 / 10000 correct (91.51)\n",
      "缩小样本精确度\n",
      "Got 4031 / 10000 correct (40.31)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n原始样本精确度\")\n",
    "check_accuracy(dilate_net2, te_original)\n",
    "print(\"缩小样本精确度\")\n",
    "check_accuracy(dilate_net2, te_zoom_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 结论：混合卷积核，可以提高改变尺寸后的精度，但会降低原有的精度，也许在1D数据中能表现更好"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
